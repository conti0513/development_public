# 📘 メモ１：ある通信インフラ現場で経験した「基地局停止事故」の教訓

## 🗓️ 発生時期
約10年以上前の案件

## 🧩 担当領域と立場

- 自分は**ソリューション部門の回線構築担当**としてプロジェクトに参画
- 担当範囲は、VLAN設計、ユーザー向け提案、申込～開通調整など
- スイッチ設定を担当する部門とは別組織で、物理的にも離れたロケーションに存在

---

## 🏢 組織・構造的な背景

- スイッチ設定・開通部門は別拠点にあり、**合併前は異なる企業文化を持つ組織同士**
- そのため、**部門間で仕様理解や運用観点にギャップ**があった
- 設定部門はレガシーな運用文化を色濃く残し、ドキュメントや運用基準も部門独自だった

---

## ⚠️ 起きたこと（要約）

- 対象の回線はもともと**家庭向けインターネットサービス**をベースにしたものを、**法人用途へ転用**したばかりの時期だった
- VLAN追加作業時に、**全体定義型のスイッチ**へ**差分投入を行ったことで、既存の重要VLANが削除**
- 結果、**都市部の公共エリアをカバーする基地局が数日間停止状態に**
- スイッチ設定部門から「削除しますが問題ありませんか？」との連絡があったが、**仕様理解の不十分さにより承認してしまった**

---

## 📣 ユーザー側・業務側の背景

- 当時、サービスは提供開始から約1年のタイミングで、**通信エリアを急速に拡大中**
- 特定施設（自治体関連を含む）を対象とした拡販フェーズであり、**スピード納品・提案重視の方針**が社内的に強かった
- ソリューション部門では、「**品質が安定している家庭用インフラをそのまま活用できる**」ことを提案の軸にしていた

---

## 🛠️ 対応後の改善

- 事故対応として謝罪・影響報告を実施し、**部門横断の改善プロジェクトを即時立ち上げ**
- 当初はExcelマクロベースで属人化していた申込情報を、**Access + VBAで構造化**
  - **申込種別（新設／追記）を明確に分類できるように設計**
  - **ユーザー調整や停波スケジュールの記録・確認が容易な構造に改善**
- VLAN再定義などの設定変更がある場合には、
  - ユーザーとの停波可能日調整
  - 対応アサイン
  - 設定当日の監視連携
  - 問題なければクローズという一連のフローを運用化

---

## ⚙️ 技術的教訓

- VLAN設計においては、「**追記可能か／全体定義型か**」という仕様把握が最重要
- GUIとCLIの混在機種では、**設定不整合や未反映が発生しやすい**
- スイッチベンダーや型番によっては、**設定ミスが即ネットワーク断に直結する仕様**であることを事前に見極めるべき
- 設定部門との距離（物理・文化的）によって、**仕様の共通理解が阻害される構造**がある

---

## 🧠 リスクの構造的理解

- 属人化された設計・設定、運用ドキュメントの未整備
- 他部署との連携フローが曖昧
- スピード優先で進めた営業フェーズと、慎重さを要する運用フェーズの**設計思想のズレ**
- 担当部門同士が**「言語の違う組織」になっていた**ことが事故を助長

---

## ✅ 学び（TIL）

- **“構成変更の瞬間”にしか爆発しない地雷は、確かに存在する**
- **家庭向け構成を法人に転用する際には、「運用思想の違い」を意識した設計が必要**
- **仕様を理解せずに「動いてるからOK」と進めるのは最大の落とし穴**
- **たとえ一担当であっても、設計と構造に踏み込む意識が未来の事故を防ぐ**

---

## 🪨 その後の歩み

- 再設計されたスキームは**以後一切の事故なく、機器のEOSまで継続運用**
- 約3年間で**数千件の構成変更・申込対応をノーインシデントで処理**
- 派手な評価を受けることはなかったが、  
  **「止まらなかったこと」「誰も気づかずに通信が守られたこと」こそが最大の成果だった**と、今は確信している

---


# 📘 メモ2：夜間SI作業で起きた保険代理店オンラインシステム障害（TIL概要）

## 🗓️ 発生時期
約20年前

## 🧩 担当と状況

- 自分は**運用部門所属のベテラン（在籍4年以上／サブリーダー）**
- メンバーは**1年未満の新人1名**
- Wチェック体制だったが、**実質1.5人体制で実施**
- 作業は**深夜のオフライン時間帯に限定される手動SI**

---

## ⚠️ 作業の特徴とミスの背景

- 作業手順は**数十ページの紙ベース**
- **ファイルリストと本手順が別ファイル**になっており、紐付けが難しい
- 手順通りに見えても、**ファイルアップロード作業が抜けやすい構造**
- 自身の作業中に、**強い眠気があり判断力低下**  
→ 結果、**対象ファイルのアップロードを漏らす**

---

## 🚨 影響

- オンラインシステムの一部機能（保険設計処理）が**約24時間停止**
- ユーザー企業より**SIerへクレームが発生**
- 内部でも「**チェック体制の不備**」「作業設計の欠陥」等が指摘される

---

## 🧠 自分への影響と判断

- この事故を契機に、**夜間作業・運用業務の限界**を強く実感
- **その後約1年で退職**し、運用からは撤退
- 原因は一人ではないが、**「責任感のある立場で事故を防げなかった」**という反省が残る

---

## ✍️ 後日追記予定

- システム構成と手順の構造的問題
- 事故後の対応（内部報告・改善提案の有無）
- なぜミスに気づけなかったのか
- この経験から得た学びと、現在の運用設計にどう活かされているか

---
# 📘 メモ3：事業会社で発生したWindowsサーバーデータ誤削除（TIL概要）

## 🗓️ 発生時期
時期不明（後日追記予定）

## 🧩 担当と役割

- 自分は**社内のWindowsサーバー管理者**
- サーバー運用・ファイル管理に責任を持つ立場で業務に従事

---

## ⚠️ 発生した事象

- オーダー系の部門があるファイルの処理依頼を提出
- → 受付担当部門（同じ部署内）
- → サーバー管理部門（自分含む）に伝達

しかしこの**一連の伝達がすべて口頭や非記録系手段**で行われたため、
- **内容の確認漏れ**
- **削除対象の誤認識**
- **手続きや承認なしの処理**

の状態で、**誤って重要なサーバーデータを削除**

---

## 📣 影響

- 業務上重要なデータが消失
- オーダー部門が一時的に業務停止
- 部門間での調整・謝罪対応が必要となり、**一定期間の混乱が発生**
- バックアップからのリカバリはできたが、**一部データは復元困難**

---

## 💡 問題の構造

- 全部門が**同一部署内に存在していたため、口頭伝達が常態化**
- 「社内だから」「いつもの流れだから」という**慣れが確認を省略させた**
- 自分も含め、**一切ログ・チケット・指示書などが存在しなかった**

---

## 🧠 学び（TIL）

- **コミュニケーションが“社内”であるほど、文書化の重要性は増す**
- **一つの部署の中で“依頼 → 実行”が完結するときこそ、確認フローが曖昧になる**
- **サーバー管理者である自分も、確認と保全策を設ける責任があった**
- 今後は、**どんな小さな作業でも「記録 →二重確認 →実行」を原則化**すべきと強く学んだ

---

## ✍️ 後日追記予定

- 具体的な削除対象とその重要性
- 依頼〜削除までのタイムライン
- 誰がどこで止められたか？どこがボトルネックだったか？
- 再発防止策と現在のルール・体制との違い

---
ありがとうございます。
詳細を受けて、**メモ3のTIL下書きを全面リビルド**しました。
Slackでの伝聞、上長確認、Windowsの仕様誤認、体調要因など、**人間・技術・組織が絡み合う構造的ミス**として整理しています。

---

```markdown
# 📘 メモ3：Slack依頼から発生したWindowsサーバーデータ誤削除（TIL概要）

## 🗓️ 発生時期
時期未記録（約◯年前、後日記載予定）

## 🧩 担当と立場

- 自分は**社内情報システム部門におけるWindowsサーバー管理者**
- 日常的に、社内部門からのデータ削除依頼・権限管理などを対応
- 削除処理については、**普段は非常に慎重な運用**を行っていた

---

## ⚠️ 発生した事象

- オーダー部門より、**Slack上で「対象フォルダをいい感じに消しておいて」**というやや曖昧な指示を受領
- 添付として**画面キャプチャもあったが、範囲が不明確**
- 担当として削除対象を自分なりに認識した上で、**上長へSlackで「この内容で削除して良いか」を確認**
- 上長からも「**いつもミスがないし大丈夫でしょう**」とSlack上でGOサインが出たため、削除を実行
- この日は**体調が優れず、慎重さが欠けた状態で作業**していた

---

## 🔄 誤解と想定のずれ

- 自分としては「**Windowsはシステムレベルで簡単に復元できる**」という認識があり、削除の実行ハードルが下がっていた
- しかし、実際に削除したファイル群は**数十GB規模**と巨大で、復元処理に**膨大な時間**がかかる
- さらにリカバリ中に**ユーザーが対象フォルダにアクセスして更新をかけてしまい、**  
→ **ファイルの世代が不一致となり、データが破損・混乱**

---

## 📣 影響

- 一部の業務データが**正確に復元されず**
- ユーザー部門から「なぜ削除されたのか」「確認は行われていたのか」などの問い合わせが発生
- 結果として、**データ保全体制への信頼低下**と、**再発防止策の整備要求**

---

## 🧠 背景と構造的な要因

- **Slackでの軽い依頼 → 軽い承認 → 実行**という**チェックの薄い流れ**
- 「体調不良」「普段は慎重だから大丈夫」という**個人評価に依存した運用判断**
- システム的には復元可能でも、**“ファイル世代管理”や“並行更新”のリスクを考慮していなかった**
- コミュニケーションも技術仕様も、**曖昧さが積み重なって事故を起こした構造**

---

## ✅ 学び（TIL）

- **「いい感じで」「軽くやっておいて」は、最も重い事故を呼ぶ魔法の言葉**
- **“普段は大丈夫”という信頼は、例外時に最大の落とし穴になる**
- **Slackなど非構造チャネルでは、「内容」「意図」「対象」「承認」を最低限明文化すべき**
- 技術的に戻せる＝業務的にも元通り、ではない
- 削除などの不可逆操作には、**状態確認／スナップショット／復元時間と影響予測**が必須

---

## ✍️ 後日追記予定

- 削除フォルダの構造と容量
- リカバリの詳細な所要時間と影響範囲
- その後の業務改善策（チェックリスト化・承認手順化など）
- 自分のメンタル面の影響・今の働き方への影響

---
```


# 📘 TIL：ADHD × PJT設計と事故防止マトリクス

## ✅ 通底する3つの事故要因

- 情報の曖昧さ（口頭・Slack・非構造）
- 責任と構造の不一致（裁量ないのに判断する構造）
- ドキュメント化されていない“意図の行間”依存

→ いずれもADHD特性にとって**事故を起こしやすい構造**

---

## 🎯 ADHD × PJT 適性マトリクス

| 項目 | 向いているPJ | 向いていないPJ |
|------|----------------|------------------|
| 情報形式 | 明文化・構造化された指示 | 口頭伝達・Slack依存・曖昧指示 |
| 作業性質 | 仕組み化・整備・再設計 | 夜間・即クレーム・即断タスク |
| ワークスタイル | ナレッジ管理・可視化型 | 柔軟対話・即応系 |
| 安定性 | 権限＝責任が明確な構造 | 責任だけ背負わされる構造 |

---

## 🧠 ADHDフレンドリーな行動5選

1. **書いてから動く**  
　→「対象・確認者・戻し方」をToDoに落とす

2. **口頭NG、必ず記録**  
　→ Slack依頼は必ずNotion/TILへ転記して咀嚼

3. **チェックはテンプレ化**

```text
[削除作業チェック]
- □ 対象パス確認済み
- □ 承認ログあり（スクショOK）
- □ 上長 or Wチェック済み
- □ リカバリ可能性・所要時間確認済み
````

4. **体調悪い日は保留ボタン**
   　→「実行」せず「可視化・相談」で止める

5. **“止めなかった”を成果にする**
   　→ 動いた成果より「構造を守った記録」をTILに残す

---

## 📌 向いてないことをやる時の注意

| 状況        | 対策                             |
| --------- | ------------------------------ |
| 手順が不完全    | 「それおかしくない？」を言語化する勇気            |
| 属人業務の巻き取り | スクリプト・チェックリスト化を前提に引き受ける        |
| 緊急対応      | 判断者にならず、判断者を呼ぶ                 |
| Slack依存PJ | チャットは必ず自分の言葉で書き直す（Notion・手帳など） |

---

## 💬 マントラ再掲（要点）

> あいまいな依頼は事故のもと
> 判断は元気なときだけ
> 信頼より手順、記憶より記録
> 動いたより、止めなかったを誇れ

---

